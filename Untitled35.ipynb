{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2BRUZrRWcNDF197vBGtUN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishekjha111/AI-codes/blob/master/Untitled35.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTxr2K8bwdEP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import easyocr\n",
        "import os\n",
        "\n",
        "# Initialize the EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])  # You can add more languages as needed\n",
        "\n",
        "# Path to the folder containing your images\n",
        "image_folder = \"path_to_image_folder\"\n",
        "\n",
        "# Function to process and extract text from an image\n",
        "def extract_text_from_image(image_path):\n",
        "    # Load the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert the image to grayscale (if needed)\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Perform any additional preprocessing (e.g., noise removal, resizing, etc.) as needed\n",
        "    # Example: resized_image = cv2.resize(gray_image, (800, 600))\n",
        "\n",
        "    # Rotate the image to improve text recognition\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, -90, 1.0)\n",
        "    rotate_image = cv2.warpAffine(image, M, (w, h))\n",
        "\n",
        "    # Use EasyOCR to extract text from the preprocessed image\n",
        "    result = reader.readtext(rotate_image)\n",
        "\n",
        "    # Extract and return the recognized text from the result\n",
        "    extracted_text = [entry[1] for entry in result]\n",
        "\n",
        "    return extracted_text\n",
        "\n",
        "# Loop through all images in the folder\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Add more extensions if needed\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        extracted_text = extract_text_from_image(image_path)\n",
        "\n",
        "        # Do something with the extracted text (e.g., print, save to a file, or further processing)\n",
        "        print(f\"Text from {filename}:\")\n",
        "        for text in extracted_text:\n",
        "            print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is one way to combine all the suggestions into a single program:\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import easyocr\n",
        "import os\n",
        "from multiprocessing import Pool\n",
        "import csv\n",
        "\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "def process_image(image_path):\n",
        "  \n",
        "  try:\n",
        "    image = cv2.imread(image_path)\n",
        "  except Exception as e:\n",
        "    print(f\"Error reading image {image_path}: {e}\")\n",
        "    return\n",
        "    \n",
        "  # Preprocessing  \n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  resized = cv2.resize(gray, (800,600))\n",
        "  \n",
        "  # OCR\n",
        "  result = reader.readtext(resized, detail=0)\n",
        "  \n",
        "  text = \"\"\n",
        "  for b in result:\n",
        "    if b[2] > 0.5:  \n",
        "      text += b[1] + \" \"\n",
        "      \n",
        "  return image_path, text\n",
        "\n",
        "def main():\n",
        "\n",
        "  image_folder = 'images'\n",
        "  image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder)]\n",
        "\n",
        "  pool = Pool(8)\n",
        "  texts = pool.map(process_image, image_paths)\n",
        "  pool.close()\n",
        "\n",
        "  with open('results.csv', 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Image','Text'])\n",
        "    writer.writerows(texts)\n",
        "\n",
        "  # Additional analysis on extracted texts\n",
        "  ...\n",
        "  \n",
        "if __name__ == '__main__':\n",
        "  main()\n",
        "```\n",
        "\n",
        "The key changes:\n",
        "\n",
        "- Uses multiprocessing pool for parallelization\n",
        "- Adds OCR confidence filtering\n",
        "- Writes extracted texts to CSV for persistence\n",
        "- Combines image loading, preprocessing and OCR in one function\n",
        "\n",
        "Let me know if any part needs more explanation!"
      ],
      "metadata": {
        "id": "7Wslc2muxzRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o41ART-Z0Ot0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are a few ways you could improve the image text extraction code:\n",
        "\n",
        "1. Add error handling for invalid/unsupported image formats:\n",
        "\n",
        "```python\n",
        "try:\n",
        "  image = cv2.imread(image_path)\n",
        "except Exception as e:\n",
        "  print(f\"Error reading image {image_path}: {e}\")\n",
        "  continue\n",
        "```\n",
        "\n",
        "2. Parallelize the processing using multiprocessing:\n",
        "\n",
        "```python\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def process_image(image_path):\n",
        "  # extract text logic\n",
        "  return extracted_text\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  pool = Pool(processes=8)\n",
        "  texts = pool.map(process_image, image_paths)\n",
        "  pool.close()\n",
        "```\n",
        "\n",
        "3. Use OCR confidence scores to filter out low confidence results\n",
        "\n",
        "```python\n",
        "result = reader.readtext(image, detail=0)\n",
        "\n",
        "text = \"\"\n",
        "for b in result:\n",
        "  if b[2] > 0.5:\n",
        "    text += b[1] + \" \"\n",
        "```\n",
        "\n",
        "4. Persist extracted text to a CSV/database for later analysis\n",
        "\n",
        "5. Add preprocessing like noise removal, deskew, resize for better OCR\n",
        "\n",
        "6. Handle landscape/portrait orientations intelligently\n",
        "\n",
        "7. Add progress tracking for long image folders\n",
        "\n",
        "8. Cache/reuse OCR model for faster processing\n",
        "\n",
        "9. Analyze/group extracted texts after processing all images"
      ],
      "metadata": {
        "id": "UDjeqtcbyAFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ifVQqL9g1NWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import easyocr\n",
        "import os\n",
        "from multiprocessing import Pool\n",
        "import csv\n",
        "import time\n",
        "\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "def process_image(image_path):\n",
        "\n",
        "  try:\n",
        "    image = cv2.imread(image_path)\n",
        "  except Exception as e:\n",
        "    print(f\"Error reading image {image_path}: {e}\")\n",
        "    return\n",
        "\n",
        "  # Preprocessing\n",
        "  gray = preprocess(image)\n",
        "\n",
        "  # OCR\n",
        "  result = reader.readtext(gray, detail=0)\n",
        "\n",
        "  text = \"\"\n",
        "  for b in result:\n",
        "    if b[2] > 0.5:\n",
        "      text += b[1] + \" \"\n",
        "\n",
        "  return image_path, text\n",
        "\n",
        "def preprocess(image):\n",
        "\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Deskew\n",
        "  gray = deskew(gray)\n",
        "\n",
        "  # Resize\n",
        "  gray = cv2.resize(gray, (800,600))\n",
        "\n",
        "  return gray\n",
        "\n",
        "def deskew(image):\n",
        "  # image deskewing logic\n",
        "  return deskewed\n",
        "\n",
        "def main():\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  image_folder = 'images'\n",
        "  image_paths = get_image_paths(image_folder)\n",
        "\n",
        "  pool = Pool(8)\n",
        "  texts = pool.map(process_image, image_paths)\n",
        "  pool.close()\n",
        "\n",
        "  write_results(texts)\n",
        "\n",
        "  end = time.time()\n",
        "  print(f'Completed in {end-start} seconds')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "Y5faqRPxxxLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Here's an updated version of the code that includes additional image processing steps such as noise removal, resizing, and adaptive thresholding to enhance OCR accuracy:\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import easyocr\n",
        "import os\n",
        "import multiprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])  # You can add more languages as needed\n",
        "\n",
        "# Path to the folder containing your images\n",
        "image_folder = \"path_to_image_folder\"\n",
        "\n",
        "# Function to process and extract text from an image\n",
        "def extract_text_from_image(image_path):\n",
        "    try:\n",
        "        # Load the image using OpenCV\n",
        "        image = cv2.imread(image_path)\n",
        "        \n",
        "        # Automatically detect and correct the orientation of the image\n",
        "        if 'deskew' in reader.model_list[0].module_list:\n",
        "            image = reader.model_list[0].module_list[0].deskew(image)\n",
        "        \n",
        "        # Convert the image to grayscale\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Perform additional preprocessing (e.g., noise removal, resizing)\n",
        "        # Noise removal using Gaussian blur\n",
        "        gray_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "        \n",
        "        # Resize the image for better OCR accuracy\n",
        "        resized_image = cv2.resize(gray_image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "        \n",
        "        # Apply adaptive thresholding to binarize the image\n",
        "        binary_image = cv2.adaptiveThreshold(resized_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "        \n",
        "        # Use EasyOCR to extract text from the preprocessed image\n",
        "        result = reader.readtext(binary_image)\n",
        "        \n",
        "        # Filter results based on confidence scores\n",
        "        high_confidence_text = [entry[1] for entry in result if entry[2] > 0.7]  # Adjust confidence threshold as needed\n",
        "        \n",
        "        return high_confidence_text\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "# Function to process images in parallel\n",
        "def process_images(image_paths):\n",
        "    extracted_text = []\n",
        "    for image_path in image_paths:\n",
        "        text = extract_text_from_image(image_path)\n",
        "        extracted_text.extend(text)\n",
        "    return extracted_text\n",
        "\n",
        "# Get a list of image file paths from the folder\n",
        "image_paths = [os.path.join(image_folder, filename) for filename in os.listdir(image_folder)\n",
        "               if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Split the image paths into chunks for parallel processing\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "image_chunks = [image_paths[i:i + num_cores] for i in range(0, len(image_paths), num_cores)]\n",
        "\n",
        "# Initialize a progress counter\n",
        "processed_count = 0\n",
        "total_images = len(image_paths)\n",
        "\n",
        "# Initialize a list to store extracted text\n",
        "all_extracted_text = []\n",
        "\n",
        "# Process images in parallel\n",
        "pool = multiprocessing.Pool(processes=num_cores)\n",
        "for extracted_text_chunk in pool.imap_unordered(process_images, image_chunks):\n",
        "    all_extracted_text.extend(extracted_text_chunk)\n",
        "    processed_count += len(image_paths)\n",
        "    print(f\"Processed {processed_count}/{total_images} images\")\n",
        "\n",
        "# Close the multiprocessing pool\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "# Create a DataFrame to store the extracted text\n",
        "df = pd.DataFrame({'Extracted Text': all_extracted_text})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('extracted_text.csv', index=False)\n",
        "\n",
        "# Analyze/group extracted texts\n",
        "# For example, you can count and print the most frequent words\n",
        "word_counts = df['Extracted Text'].str.split().explode().value_counts()\n",
        "print(\"Most frequent words:\")\n",
        "print(word_counts.head(10))\n",
        "```\n",
        "\n",
        "This code now includes Gaussian blur for noise removal, resizing for better OCR accuracy, and adaptive thresholding for binarization. Adjust the parameters as needed for your specific images."
      ],
      "metadata": {
        "id": "IMxRAT7T0Qyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ".\n",
        "\n",
        "**Assumptions:**\n",
        "1. We have a folder named \"sample_images\" containing various images with text.\n",
        "2. The images may have varying levels of noise.\n",
        "3. We will resize the images to a width of 800 pixels for better OCR accuracy.\n",
        "4. We will apply adaptive thresholding to binarize the images.\n",
        "5. We will set a confidence threshold of 0.7 to filter out low-confidence OCR results.\n",
        "6. We will save the extracted text to a CSV file named \"extracted_text.csv\".\n",
        "7. We will analyze the extracted text by counting the most frequent words.\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import easyocr\n",
        "import os\n",
        "import multiprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Path to the folder containing sample images (hypothetical)\n",
        "image_folder = \"sample_images\"\n",
        "\n",
        "# Function to process and extract text from an image\n",
        "def extract_text_from_image(image_path):\n",
        "    try:\n",
        "        # Load the image using OpenCV\n",
        "        image = cv2.imread(image_path)\n",
        "        \n",
        "        # Automatically detect and correct the orientation of the image (hypothetical assumption)\n",
        "        if 'deskew' in reader.model_list[0].module_list:\n",
        "            image = reader.model_list[0].module_list[0].deskew(image)\n",
        "        \n",
        "        # Convert the image to grayscale\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Perform additional preprocessing (hypothetical assumptions)\n",
        "        # Noise removal using Gaussian blur\n",
        "        gray_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "        \n",
        "        # Resize the image to a fixed width of 800 pixels\n",
        "        resized_image = cv2.resize(gray_image, (800, int(800 * gray_image.shape[0] / gray_image.shape[1])))\n",
        "        \n",
        "        # Apply adaptive thresholding to binarize the image\n",
        "        binary_image = cv2.adaptiveThreshold(resized_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "        \n",
        "        # Use EasyOCR to extract text from the preprocessed image\n",
        "        result = reader.readtext(binary_image)\n",
        "        \n",
        "        # Filter results based on a hypothetical confidence threshold of 0.7\n",
        "        high_confidence_text = [entry[1] for entry in result if entry[2] > 0.7]\n",
        "        \n",
        "        return high_confidence_text\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "# Function to process images in parallel\n",
        "def process_images(image_paths):\n",
        "    extracted_text = []\n",
        "    for image_path in image_paths:\n",
        "        text = extract_text_from_image(image_path)\n",
        "        extracted_text.extend(text)\n",
        "    return extracted_text\n",
        "\n",
        "# Get a list of image file paths from the hypothetical sample folder\n",
        "image_paths = [os.path.join(image_folder, filename) for filename in os.listdir(image_folder)\n",
        "               if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Split the image paths into chunks for parallel processing\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "image_chunks = [image_paths[i:i + num_cores] for i in range(0, len(image_paths), num_cores)]\n",
        "\n",
        "# Initialize a progress counter\n",
        "processed_count = 0\n",
        "total_images = len(image_paths)\n",
        "\n",
        "# Initialize a list to store extracted text\n",
        "all_extracted_text = []\n",
        "\n",
        "# Process images in parallel\n",
        "pool = multiprocessing.Pool(processes=num_cores)\n",
        "for extracted_text_chunk in pool.imap_unordered(process_images, image_chunks):\n",
        "    all_extracted_text.extend(extracted_text_chunk)\n",
        "    processed_count += len(image_paths)\n",
        "    print(f\"Processed {processed_count}/{total_images} images\")\n",
        "\n",
        "# Close the multiprocessing pool\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "# Create a DataFrame to store the extracted text\n",
        "df = pd.DataFrame({'Extracted Text': all_extracted_text})\n",
        "\n",
        "# Save the DataFrame to a hypothetical CSV file\n",
        "df.to_csv('extracted_text.csv', index=False)\n",
        "\n",
        "# Analyze/group extracted texts (hypothetical)\n",
        "# For example, count and print the most frequent words\n",
        "word_counts = df['Extracted Text'].str.split().explode().value_counts()\n",
        "print(\"Most frequent words:\")\n",
        "print(word_counts.head(10))\n",
        "```\n",
        "\n",
        "This hypothetical example assumes certain image preprocessing steps, confidence threshold, and output file names for demonstration purposes. Actual results may require adjustments based on real data and use cases."
      ],
      "metadata": {
        "id": "xA8Hn9Mv1O2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! To save the extracted text as a result in a CSV file, you can modify the code as follows to include text extraction and CSV file writing:\n",
        "\n",
        "```python\n",
        "import cv2\n",
        "import easyocr\n",
        "import os\n",
        "import multiprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "\n",
        "# Path to the folder containing sample images (hypothetical)\n",
        "image_folder = \"sample_images\"\n",
        "\n",
        "# Function to process and extract text from an image\n",
        "def extract_text_from_image(image_path):\n",
        "    try:\n",
        "        # Load the image using OpenCV\n",
        "        image = cv2.imread(image_path)\n",
        "        \n",
        "        # Automatically detect and correct the orientation of the image (hypothetical assumption)\n",
        "        if 'deskew' in reader.model_list[0].module_list:\n",
        "            image = reader.model_list[0].module_list[0].deskew(image)\n",
        "        \n",
        "        # Convert the image to grayscale\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Perform additional preprocessing (hypothetical assumptions)\n",
        "        # Noise removal using Gaussian blur\n",
        "        gray_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "        \n",
        "        # Resize the image to a fixed width of 800 pixels\n",
        "        resized_image = cv2.resize(gray_image, (800, int(800 * gray_image.shape[0] / gray_image.shape[1])))\n",
        "        \n",
        "        # Apply adaptive thresholding to binarize the image\n",
        "        binary_image = cv2.adaptiveThreshold(resized_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "        \n",
        "        # Use EasyOCR to extract text from the preprocessed image\n",
        "        result = reader.readtext(binary_image)\n",
        "        \n",
        "        # Filter results based on a hypothetical confidence threshold of 0.7\n",
        "        high_confidence_text = [entry[1] for entry in result if entry[2] > 0.7]\n",
        "        \n",
        "        return high_confidence_text\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "# Function to process images in parallel\n",
        "def process_images(image_paths):\n",
        "    extracted_text = []\n",
        "    for image_path in image_paths:\n",
        "        text = extract_text_from_image(image_path)\n",
        "        extracted_text.extend(text)\n",
        "    return extracted_text\n",
        "\n",
        "# Get a list of image file paths from the hypothetical sample folder\n",
        "image_paths = [os.path.join(image_folder, filename) for filename in os.listdir(image_folder)\n",
        "               if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Split the image paths into chunks for parallel processing\n",
        "num_cores = multiprocessing.cpu_count()\n",
        "image_chunks = [image_paths[i:i + num_cores] for i in range(0, len(image_paths), num_cores)]\n",
        "\n",
        "# Initialize a progress counter\n",
        "processed_count = 0\n",
        "total_images = len(image_paths)\n",
        "\n",
        "# Initialize a list to store extracted text\n",
        "all_extracted_text = []\n",
        "\n",
        "# Process images in parallel\n",
        "pool = multiprocessing.Pool(processes=num_cores)\n",
        "for extracted_text_chunk in pool.imap_unordered(process_images, image_chunks):\n",
        "    all_extracted_text.extend(extracted_text_chunk)\n",
        "    processed_count += len(image_paths)\n",
        "    print(f\"Processed {processed_count}/{total_images} images\")\n",
        "\n",
        "# Close the multiprocessing pool\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n",
        "# Create a DataFrame to store the extracted text\n",
        "df = pd.DataFrame({'Extracted Text': all_extracted_text})\n",
        "\n",
        "# Save the DataFrame to a hypothetical CSV file\n",
        "output_csv = 'extracted_text.csv'\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "# Analyze/group extracted texts (hypothetical)\n",
        "# For example, count and print the most frequent words\n",
        "word_counts = df['Extracted Text'].str.split().explode().value_counts()\n",
        "print(\"Most frequent words:\")\n",
        "print(word_counts.head(10))\n",
        "\n",
        "print(f\"Extracted text saved to {output_csv}\")\n",
        "```\n",
        "\n",
        "This code will save the extracted text as a CSV file named \"extracted_text.csv\" in the same directory where the script is run. The CSV file will contain a column labeled \"Extracted Text\" with the extracted text results."
      ],
      "metadata": {
        "id": "92jC9pgC1VV2"
      }
    }
  ]
}